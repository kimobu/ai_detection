{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9746f0-33f0-49ff-a977-17a00b70c02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c3cf6a-4142-466b-8eec-23b630193509",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from elasticquery import ElasticQuery\n",
    "from elasticsearch_dsl import Q\n",
    "import polars as pl\n",
    "import logging\n",
    "import json\n",
    "import ast\n",
    "import asyncio\n",
    "\n",
    "pl.Config.set_tbl_rows(100)\n",
    "pl.Config.set_fmt_str_lengths(1000)\n",
    "\n",
    "eq = ElasticQuery(host=\"10.10.10.20\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775ebd57-6693-490b-b01b-77bf80e476a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = Q('bool', must=[\n",
    "        Q('match', **{'event.dataset': 'esf'}),\n",
    "        Q('match', **{'event.action': 'exec'}),\n",
    "    ])\n",
    "\n",
    "df = eq.search(query, start_date=\"2024-11-21T23:56:48Z\", end_date=\"2024-11-22T12:04:33Z\")\n",
    "# if using the demo data, do the following instead\n",
    "# df = pl.read_csv(\"demo_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ae8f6c-4024-41b3-841b-6d733d2af85f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db3b46f-d866-43ce-9b65-1cf2ce202b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save before marking\n",
    "df.write_csv(\"demo_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47cd6c5-a252-42e2-ad76-d2aa5ca00577",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [\n",
    "    (df['host.name'] == 'scr-office-imac.local') & (df['process.group_leader.pid'].is_in([11138, 11181, 12829, 11298, 10957, 12826])),\n",
    "    (df['host.name'] == 'scr-it-mac.local') & (df['process.group_leader.pid'].is_in([12951, 12520, 12353, 14703, 12658, 12532, 14705]))\n",
    "]\n",
    "\n",
    "df = df.with_columns(\n",
    "    pl.when(conditions[0] | conditions[1])\n",
    "      .then(1)\n",
    "      .otherwise(0)\n",
    "      .alias(\"malicious\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669439d5-a420-4cd3-84a9-9fc4970c3fbe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query = Q('bool', must=[\n",
    "        Q('match', **{'event.code': '8000'})\n",
    "])\n",
    "user_df = eq.search(query, start_date=\"2024-11-21\", end_date=\"2024-11-22\")\n",
    "user_df = user_df.unique(subset=[\"user.name\"])\n",
    "user_df_filtered = user_df.select([\"user.name\", \"user.department\", \"user.title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2bc1fc-b483-4291-ae1a-8e2d5d83fa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = user_df_filtered.join(df, on=\"user.name\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f25451-6b04-4dd3-854f-f85d0e59c149",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt import GPT\n",
    "\n",
    "gpt = GPT()\n",
    "\n",
    "async def process_strings_and_analyze_concurrently(df):\n",
    "    async def process_single_group(group_key, group_df):\n",
    "        try:\n",
    "            # Extract the grouping columns\n",
    "            host_name, group_leader_pid = group_key\n",
    "\n",
    "            # Collect relevant fields from the group\n",
    "            collected_data = group_df.sort(\"@timestamp\").select(\n",
    "                [\"process.pid\", \"process.parent.pid\", \"process.command_line\", \"process.parent.name\"]\n",
    "            ).to_pandas().to_markdown()\n",
    "            \n",
    "            user_message = f\"\"\"\n",
    "                    Beginning of commands for analysis:\n",
    "                    User name: {group_df[\"user.name\"].unique()[0]}\n",
    "                    User department: {group_df[\"user.department\"].unique()[0]}\n",
    "                    User title: {group_df[\"user.title\"].unique()[0]}\n",
    "                    OS Type: {group_df[\"host.os.family\"][0]}\n",
    "                    Hostname: {group_df[\"host.name\"][0]}\n",
    "                    Processes: {collected_data}\n",
    "                    \"\"\"\n",
    "\n",
    "            # Check the length of the message\n",
    "            max_length = 1048576  # Maximum allowed length for the message\n",
    "            if len(user_message) > max_length:\n",
    "                print(f\"Group {group_key} message exceeds max length. Splitting into smaller chunks.\")\n",
    "\n",
    "                # Split the DataFrame into smaller chunks\n",
    "                chunk_size = len(group_df) // (len(user_message) // max_length + 1)\n",
    "                chunks = [group_df[i:i + chunk_size] for i in range(0, len(group_df), chunk_size)]\n",
    "\n",
    "                # Process each chunk separately and combine results\n",
    "                chunk_results = []\n",
    "                for chunk in chunks:\n",
    "                    chunk_data = chunk.sort(\"@timestamp\").select(\n",
    "                        [\"process.pid\", \"process.parent.pid\", \"process.command_line\", \"process.parent.name\"]\n",
    "                    ).to_pandas().to_markdown()\n",
    "                    \n",
    "                    chunk_message = f\"\"\"\n",
    "                            Beginning of commands for analysis (chunked):\n",
    "                            User name: {chunk[\"user.name\"].unique()[0]}\n",
    "                            User department: {chunk[\"user.department\"].unique()[0]}\n",
    "                            User title: {chunk[\"user.title\"].unique()[0]}\n",
    "                            OS Type: {chunk[\"host.os.family\"][0]}\n",
    "                            Hostname: {chunk[\"host.name\"][0]}\n",
    "                            Processes: {chunk_data}\n",
    "                            \"\"\"\n",
    "                    result = await gpt.analyze(chunk_message)\n",
    "                    chunk_results.append(result)\n",
    "\n",
    "                # Combine results from all chunks\n",
    "                combined_result = {\n",
    "                    \"analysis\": \" \".join(chunk['analysis'] for chunk in chunk_results),\n",
    "                    \"suspicious_score\": max(chunk['suspicious_score'] for chunk in chunk_results),\n",
    "                }\n",
    "                any_suspicious = any(chunk['verdict'] == 'suspicious' for chunk in chunk_results)\n",
    "                combined_result['mitre_tag'] = []\n",
    "\n",
    "                for chunk in chunk_results:\n",
    "                    mitre_tags = chunk.get('mitre_tag', [])\n",
    "                    if isinstance(mitre_tags, str):\n",
    "                        mitre_tags = ast.literal_eval(mitre_tags)\n",
    "                    for tag in mitre_tags:\n",
    "                        if tag not in combined_result['mitre_tag']:\n",
    "                            combined_result['mitre_tag'].append(tag)\n",
    "\n",
    "                combined_result['verdict'] = 'suspicious' if any_suspicious else 'benign'\n",
    "            else:\n",
    "                # If within allowed length, process normally\n",
    "                result = await gpt.analyze(user_message)\n",
    "                combined_result = result\n",
    "                if isinstance(combined_result['mitre_tag'], str):\n",
    "                    combined_result['mitre_tag'] = ast.literal_eval(combined_result['mitre_tag'])\n",
    "\n",
    "            # Include grouping keys in the result\n",
    "            combined_result['host.name'] = host_name\n",
    "            combined_result['process.group_leader.pid'] = group_leader_pid\n",
    "\n",
    "            return combined_result\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing group {group_key}: {e}\")\n",
    "            return {\n",
    "                \"host.name\": host_name,\n",
    "                \"process.group_leader.pid\": group_leader_pid,\n",
    "                \"error\": str(e),\n",
    "            }\n",
    "\n",
    "    # Group by `host.name` and `process.group_leader.pid`\n",
    "    grouped = df.group_by([\"host.name\", \"process.group_leader.pid\"])\n",
    "\n",
    "    # Create tasks for each group\n",
    "    tasks = [\n",
    "        process_single_group(group_key, group_df)\n",
    "        for group_key, group_df in grouped\n",
    "    ]\n",
    "\n",
    "    # Process all groups asynchronously\n",
    "    results = await asyncio.gather(*tasks)\n",
    "\n",
    "    return pl.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad6641e-e0dd-4d81-abc9-a455312ab6f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_df = await process_strings_and_analyze_concurrently(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271d997c-7d0a-4c7a-a07e-d9e4dbd4d4a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_df = results_df.cast({\"process.group_leader.pid\": pl.UInt64 })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc5ab52-d219-460b-87b9-df78b94b1937",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5732bc6b-6d87-4524-8b7e-6ea66e6ac437",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_results_df = merged_df.join(results_df,\n",
    "                                 on=[\"host.name\", \"process.group_leader.pid\"],\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59350d13-1508-430b-b545-6f7ae467076b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_results_df = final_results_df.with_columns(\n",
    "    (pl.col(\"malicious\").cast(pl.Int64)).alias(\"malicious_binary\")\n",
    ")\n",
    "\n",
    "final_results_df = final_results_df.with_columns(\n",
    "    pl.when(pl.col(\"verdict\") == \"suspicious\")\n",
    "    .then(1)\n",
    "    .otherwise(0)\n",
    "    .alias(\"verdict_binary\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba1fa17-d935-40e0-8f1e-aab10542bf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746ead9b-1364-4165-bc9f-3a07014e9d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import polars as pl\n",
    "\n",
    "\n",
    "grouped_by_host = (\n",
    "    final_results_df.group_by([\"host.name\", \"process.group_leader.pid\"])\n",
    "    .agg(pl.col(\"verdict_binary\").first(), pl.col(\"malicious_binary\").first())\n",
    ")\n",
    "\n",
    "grouped_data = (\n",
    "    grouped_by_host.group_by([\"verdict_binary\", \"malicious_binary\"])\n",
    "    .agg(pl.len().alias(\"count\"))\n",
    "    .join(pl.DataFrame({\n",
    "        \"verdict_binary\": [0, 0, 1, 1],\n",
    "        \"malicious_binary\": [0, 1, 0, 1]\n",
    "    }), on=[\"verdict_binary\", \"malicious_binary\"], how=\"outer\")\n",
    "    .fill_null(0)\n",
    ")\n",
    "\n",
    "# Construct Confusion Matrix\n",
    "confusion_matrix = np.zeros((2, 2), dtype=int)\n",
    "\n",
    "for row in grouped_data.iter_rows(named=True):\n",
    "    verdict = int(row[\"verdict_binary_right\"])\n",
    "    malicious = int(row[\"malicious_binary_right\"])\n",
    "    count = int(row[\"count\"])\n",
    "    confusion_matrix[verdict, malicious] = count\n",
    "\n",
    "sns.heatmap(confusion_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.xlabel(\"Actual (Malicious Binary)\")\n",
    "plt.ylabel(\"Predicted (Verdict Binary)\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xticks([0.5, 1.5], [\"0\", \"1\"], rotation=0)\n",
    "plt.yticks([0.5, 1.5], [\"0\", \"1\"], rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e3aaba-a83e-43e5-a891-f9b56bcf8704",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_by_host.filter((pl.col(\"verdict_binary\") == 0) & (pl.col(\"malicious_binary\") == 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9364324a-9cd5-4563-8cfd-a00684ddb7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results_df.filter(pl.col(\"process.group_leader.pid\").is_in([12949, 11169, 11176, 11295, 12828, 14703])).select([\"verdict_binary\", \"malicious_binary\", \"suspicious_score\",  \"process.command_line\", \"process.group_leader.pid\", \"host.name\", \"analysis\", \"user.department\", \"user.title\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac53452-da1c-4b90-ba35-7f19f6ac665b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pl.Config(\n",
    "    tbl_formatting=\"MARKDOWN\",\n",
    "    tbl_hide_column_data_types=True,\n",
    "    tbl_hide_dataframe_shape=True,\n",
    "    ):\n",
    "    pl.Config.set_tbl_width_chars(12000)  \n",
    "    print(final_results_df.filter(pl.col(\"verdict_binary\") == 0)['process.command_line'].value_counts().sort(by=\"count\").tail())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
